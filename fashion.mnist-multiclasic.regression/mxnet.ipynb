{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import nd, autograd as ag, gluon\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import init\n",
    "from mxnet import image\n",
    "\n",
    "from dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: '3.5.2 (default, Nov 23 2017, 16:37:01) \\n[GCC 5.4.0 20160609]'\n",
      "numpy: '1.15.1'\n",
      "pandas: '0.23.4'\n",
      "mxnet: '1.2.1'\n"
     ]
    }
   ],
   "source": [
    "print(\"python: %r\" % sys.version)\n",
    "print(\"numpy: %r\" % np.__version__)\n",
    "#print(\"matplotlib: %r\" % plt.__version__)\n",
    "print(\"pandas: %r\" % pd.__version__)\n",
    "print(\"mxnet: %r\" % mx.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctx = mx.gpu(0)\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1oAAABcCAYAAAB3E8QeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7f75218fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[['pullover'],\n",
       " ['ankle boot'],\n",
       " ['shirt'],\n",
       " ['t-shirt'],\n",
       " ['dress,'],\n",
       " ['coat'],\n",
       " ['coat'],\n",
       " ['sandal'],\n",
       " ['coat'],\n",
       " ['bag']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(os.environ[\"HOME\"] + '/.datasets/base/fashion-mnist/')\n",
    "train_img,train_labels = dl.get_data(kind='train')\n",
    "test_img,test_labels = dl.get_data(kind='t10k')\n",
    "\n",
    "DataLoader.show_images(train_img[0:10])\n",
    "DataLoader.get_labels(train_labels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 修改为float以便求导，除以255做归一化\n",
    "train_img_nd = nd.array(train_img).astype(np.float32)/255\n",
    "train_lab_nd = nd.array(train_labels).astype(np.float32)\n",
    "test_img_nd = nd.array(test_img).astype(np.float32)/255\n",
    "test_lab_nd = nd.array(test_labels).astype(np.float32)\n",
    "\n",
    "def data_iter(batch_size=100, kind='train'):\n",
    "    if kind != 'train':\n",
    "        idx = list(range(len(test_labels)))\n",
    "        for i in range(0,len(test_labels), batch_size):\n",
    "            j = nd.array(idx[i:min(i+batch_size,len(test_labels))])\n",
    "            yield nd.take(test_img_nd,j).as_in_context(ctx), nd.take(test_lab_nd,j).as_in_context(ctx)\n",
    "    else:\n",
    "        idx = list(range(len(train_labels)))\n",
    "        for i in range(0,len(train_labels), batch_size):\n",
    "            j = nd.array(idx[i:min(i+batch_size,len(train_labels))])\n",
    "            yield nd.take(train_img_nd,j).as_in_context(ctx), nd.take(train_lab_nd,j).as_in_context(ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_root = \"~/.mxnet/datasets/fashion-mnist\"\n",
    "mnist_train = gluon.data.vision.FashionMNIST(root=data_root, train=True, transform=None)\n",
    "mnist_test = gluon.data.vision.FashionMNIST(root=data_root, train=False, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mxnet.gluon.data.vision.datasets.FashionMNIST"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FashionMNIST 使用方法：** \n",
    "\n",
    "mnist_train/test 可以这样访问：\n",
    "\n",
    "- `mnist_train[0]` : ([28,28,1],label)\n",
    "- `mnist_train[0:10]`: ([10,28,28,1], (10,)) —— **为什么要这么玩**\n",
    "- 支持 iter 访问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'> <class 'mxnet.ndarray.ndarray.NDArray'> <class 'numpy.int32'> (28, 28, 1) ()\n"
     ]
    }
   ],
   "source": [
    "a = mnist_train[0]\n",
    "print(type(a),type(a[0]),type(a[1]),a[0].shape,a[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'> <class 'mxnet.ndarray.ndarray.NDArray'> <class 'numpy.ndarray'> (10, 28, 28, 1) (10,)\n"
     ]
    }
   ],
   "source": [
    "b = mnist_train[0:10]\n",
    "print(type(b),type(b[0]),type(b[1]),b[0].shape,b[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 28, 28, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = nd.transpose(b[0].astype('float32'), (0,3,1,2)) # 0,3,1,2 意思是原来的位置，如何放到现在的位置\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(10, 1, 28, 28)： 整理成 nd.Convolution(data) 中 data 的格式，data（即图片）要求格式是：  \n",
    "(batchsize, channel, height, width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Net\n",
    "\n",
    "$$\\boldsymbol{\\hat y} = net({\\boldsymbol x})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_input = 28*28\n",
    "num_output = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wb\n",
    "\n",
    "无隐层\n",
    "\n",
    "$$net({\\boldsymbol x}) = {\\boldsymbol{x}}\\ {W} + {\\boldsymbol{b}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = nd.random_normal(shape=(num_input, num_output),ctx=ctx)\n",
    "b = nd.random_normal(shape=(num_output),ctx=ctx)\n",
    "\n",
    "wb_params = [W,b]\n",
    "for p in wb_params:\n",
    "    p.attach_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def net_wb(X):\n",
    "    return nd.dot(X,W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP\n",
    "\n",
    "加入1个隐层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    return nd.maximum(X,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_hidden = 256\n",
    "weight_scale = .01\n",
    "\n",
    "# MXNet 的公式是 y=XW+b，吴恩达的公式是 y=WX+b，所以两者W的shape定义是相反的。\n",
    "W1 = nd.random_normal(shape=(num_input,num_hidden), scale=weight_scale,ctx=ctx)\n",
    "b1 = nd.zeros(num_hidden,ctx=ctx)\n",
    "\n",
    "W2 = nd.random_normal(shape=(num_hidden,num_output),scale=weight_scale,ctx=ctx)\n",
    "b2 = nd.zeros(num_output,ctx=ctx)\n",
    "\n",
    "mlp_params = [W1,b1,W2,b2]\n",
    "for p in mlp_params:\n",
    "    p.attach_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def net_mlp(X):\n",
    "    X = X.reshape((-1, num_input))\n",
    "    h1 = relu(nd.dot(X,W1) + b1)\n",
    "    output = nd.dot(h1,W2) + b2\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP_gluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_net = gluon.nn.Sequential()\n",
    "with mlp_net.name_scope():\n",
    "    mlp_net.add(gluon.nn.Dense(256, activation=\"relu\"))\n",
    "    mlp_net.add(gluon.nn.Dropout(0.5))\n",
    "    mlp_net.add(gluon.nn.Dense(10))\n",
    "mlp_net.initialize(ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def net_mlp_gluon(X):\n",
    "    return mlp_net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_scale = .01\n",
    "\n",
    "# output channels = 20, kernel = (5,5)\n",
    "lenet_W1 = nd.random_normal(shape=(20,1,5,5), scale=weight_scale, ctx=ctx)\n",
    "lenet_b1 = nd.zeros(lenet_W1.shape[0], ctx=ctx)\n",
    "\n",
    "# output channels = 50, kernel = (3,3)\n",
    "lenet_W2 = nd.random_normal(shape=(50,20,3,3), scale=weight_scale, ctx=ctx)\n",
    "lenet_b2 = nd.zeros(lenet_W2.shape[0], ctx=ctx)\n",
    "\n",
    "# output dim = 128\n",
    "lenet_W3 = nd.random_normal(shape=(1250, 128), scale=weight_scale, ctx=ctx)\n",
    "lenet_b3 = nd.zeros(lenet_W3.shape[1], ctx=ctx)\n",
    "\n",
    "# output dim = 10\n",
    "lenet_W4 = nd.random_normal(shape=(lenet_W3.shape[1], 10), scale=weight_scale, ctx=ctx)\n",
    "lenet_b4 = nd.zeros(lenet_W4.shape[1], ctx=ctx)\n",
    "\n",
    "lenet_params = [lenet_W1, lenet_b1, lenet_W2, lenet_b2, lenet_W3, lenet_b3, lenet_W4, lenet_b4]\n",
    "for param in lenet_params:\n",
    "    param.attach_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def net_lenet(X, verbose=False):    \n",
    "    # 第一层卷积\n",
    "    h1_conv = nd.Convolution(\n",
    "        data=X, weight=lenet_W1, bias=lenet_b1, kernel=lenet_W1.shape[2:], num_filter=lenet_W1.shape[0])\n",
    "    h1_activation = nd.relu(h1_conv)\n",
    "    h1 = nd.Pooling(\n",
    "        data=h1_activation, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "    # 第二层卷积\n",
    "    h2_conv = nd.Convolution(\n",
    "        data=h1, weight=lenet_W2, bias=lenet_b2, kernel=lenet_W2.shape[2:], num_filter=lenet_W2.shape[0])\n",
    "    h2_activation = nd.relu(h2_conv)\n",
    "    h2 = nd.Pooling(data=h2_activation, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "    h2 = nd.flatten(h2)\n",
    "    # 第一层全连接\n",
    "    h3_linear = nd.dot(h2, lenet_W3) + lenet_b3\n",
    "    h3 = nd.relu(h3_linear)\n",
    "    # 第二层全连接\n",
    "    h4_linear = nd.dot(h3, lenet_W4) + lenet_b4\n",
    "    if verbose:\n",
    "        print('1st conv block:', h1.shape)\n",
    "        print('2nd conv block:', h2.shape)\n",
    "        print('1st dense:', h3.shape)\n",
    "        print('2nd dense:', h4_linear.shape)\n",
    "        print('output:', h4_linear)\n",
    "    return h4_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet_gluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lenet = nn.Sequential()\n",
    "with lenet.name_scope():\n",
    "    lenet.add(\n",
    "        nn.Conv2D(channels=20, kernel_size=5, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        nn.Conv2D(channels=50, kernel_size=3, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        nn.Flatten(),\n",
    "        nn.Dense(128, activation=\"relu\"),\n",
    "        nn.Dense(10)\n",
    "    )\n",
    "lenet.initialize(ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def net_lenet_gluon(X):\n",
    "    return lenet(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG_gluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arch_A = ((1,64),(1,128),(2,256),(2,512),(2,512))\n",
    "arch_B = ((2,64),(2,128),(2,256),(2,512),(2,512))\n",
    "arch_D = ((2,64),(2,128),(3,256),(3,512),(3,512))\n",
    "arch_E = ((2,64),(2,128),(4,256),(4,512),(4,512))\n",
    "\n",
    "def vgg_stack(arch):\n",
    "    out = nn.Sequential()\n",
    "    for (num_convs, channels) in arch:\n",
    "        seq = nn.Sequential()\n",
    "        for _ in range(num_convs):\n",
    "            seq.add(nn.Conv2D(channels=channels,kernel_size=3,\n",
    "                          padding=1,activation='relu'))\n",
    "        seq.add(nn.MaxPool2D(pool_size=2, strides=2))\n",
    "        out.add(seq)\n",
    "    return out\n",
    "    \n",
    "vgg_net = nn.Sequential()\n",
    "with vgg_net.name_scope():\n",
    "    vgg_net.add(\n",
    "        vgg_stack(arch_A),\n",
    "        nn.Flatten(),\n",
    "        nn.Dense(4096, activation='relu'),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Dense(4096, activation='relu'),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Dense(10))\n",
    "vgg_net.initialize(ctx=ctx, init=init.Xavier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def net_vgg_gluon(X):\n",
    "    return vgg_net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **net( )**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data shape: (batchsize, height, width, channel)\n",
    "# out  shape: (batchsize, channel, height, width)\n",
    "def resize_img(data, resize=None):\n",
    "    if resize:\n",
    "        n = data.shape[0]\n",
    "        new_data = nd.zeros((n, resize, resize, data.shape[3]))\n",
    "        for i in range(n):\n",
    "            new_data[i] = image.imresize(data[i].as_in_context(mx.cpu()), \n",
    "                                         resize, resize)\n",
    "        data = new_data\n",
    "    return nd.transpose(data.astype('float32'),(0,3,1,2))/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def net(data, net_type='wb'):\n",
    "    data = data.as_in_context(ctx)\n",
    "    # data.shape: 100*784\n",
    "    if net_type == 'wb':\n",
    "        return net_wb(data)\n",
    "    elif net_type == 'mlp':\n",
    "        return net_mlp(data)\n",
    "    elif net_type == 'mlp_gluon':\n",
    "        return net_mlp_gluon(data)\n",
    "    elif net_type == 'lenet':\n",
    "        data = data.reshape((data.shape[0],1,28,28))\n",
    "        return net_lenet(data.astype('float32'))\n",
    "    elif net_type == 'lenet_gluon':\n",
    "        data = data.reshape((data.shape[0],1,28,28))\n",
    "        return net_lenet_gluon(data.astype('float32'))\n",
    "    elif net_type == 'vgg_gluon':\n",
    "        data = data.reshape((data.shape[0],28,28,1))\n",
    "        data = resize_img(data, resize=96)\n",
    "        data = data.as_in_context(ctx)\n",
    "        return net_vgg_gluon(data.astype('float32'))\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$softmax(\\mathbf{z})_j = \\frac{e^{z_j}}{\\sum_{k=1}^K e^{z_k}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    e = nd.exp(X)\n",
    "    t = nd.sum(e, axis=1, keepdims=True)\n",
    "    return e/t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交叉熵 Cross Entropy: \n",
    "\n",
    "$$-\\sum_i \\log p_{i,{label}_i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy(yhat,y):\n",
    "    # yhat数组（10个元素）中取出索引为 y 的那个元素\n",
    "    # rt = - nd.log(nd.pick(yhat,y)) \n",
    "    rt = - nd.pick(nd.log(yhat),y)\n",
    "    rt = nd.mean(rt, axis=0, exclude=True)\n",
    "    return rt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gluon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gluon.loss.xxx\n",
    "\n",
    "- L1Loss: $$L = \\sum_i \\vert {pred}_i - {label}_i \\vert.$$\n",
    "- L2Loss: $$L = \\frac{1}{2} \\sum_i \\vert {pred}_i - {label}_i \\vert^2.$$\n",
    "- SigmoidBinaryCrossEntropyLoss: $$\\begin{align}\\begin{aligned}prob = \\frac{1}{1 + \\exp(-{pred})}\\\\L = - \\sum_i {label}_i * \\log({prob}_i) + (1 - {label}_i) * \\log(1 - {prob}_i)\\end{aligned}\\end{align}$$\n",
    "- SoftmaxCrossEntropyLoss: $$\\begin{align}\\begin{aligned}\\DeclareMathOperator{softmax}{softmax}\\\\p = \\softmax({pred})\\\\L = -\\sum_i \\log p_{i,{label}_i}\\end{aligned}\\end{align}$$\n",
    "- KLDivLoss: $$L = \\sum_i {label}_i * \\big[\\log({label}_i) - {pred}_i\\big]$$\n",
    "- CTCLoss\n",
    "- HuberLoss\n",
    "- HingeLoss\n",
    "- SquaredHingeLoss\n",
    "- LogisticLoss:$$L = \\sum_i \\log(1 + \\exp(- {pred}_i \\cdot {label}_i))$$\n",
    "- TripletLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_softmax_ce = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer/Trainner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SGD(params, lr):\n",
    "    for p in params:\n",
    "        p[:] = p - lr*p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = mx.optimizer.SGD()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_trainer(net):\n",
    "    return gluon.Trainer(net.collect_params(), \n",
    "                        'sgd', \n",
    "                        {'learning_rate': 0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(yhat,y):\n",
    "    return nd.mean(yhat.argmax(axis=1)==y).asscalar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epochs=5, learning_rate=.1, net_type='wb', params=wb_params, trainer=None):\n",
    "    t1 = datetime.datetime.now()\n",
    "    prev_time = datetime.datetime.now()\n",
    "    for e in range(epochs):\n",
    "        train_loss = 0.\n",
    "        train_accu = 0.\n",
    "        test_accu  = 0.\n",
    "\n",
    "        i = 0\n",
    "        for data,label in data_iter(batch_size=batch_size):\n",
    "            i += 1\n",
    "            print('\\r%4d %d%%' % (i, 100*i/(train_img.shape[0]/batch_size)), end='')\n",
    "            with ag.record():\n",
    "                yhat = net(data, net_type)\n",
    "                # 首选mxnet的loss：\n",
    "                # mxnet的loss，W、b的均值不变、方差变小\n",
    "                # 自己手写的loss会让W、b的均值单调递增，最后变为nan —— learning rate 小一点可以拖后变nan的次数，但早晚也是变nan\n",
    "                if 1:\n",
    "                    loss = loss_softmax_ce(yhat,label)\n",
    "                else:\n",
    "                    loss  = cross_entropy(softmax(yhat),label)\n",
    "            loss.backward()\n",
    "            if trainer == None:\n",
    "                SGD(params, learning_rate/batch_size)\n",
    "            else:\n",
    "                trainer.step(batch_size)\n",
    "            train_loss += nd.mean(loss).asscalar()\n",
    "            train_accu += accuracy(yhat,label)\n",
    "        #print(\"\\r\\nyhat sum:%f, var:%f, mean:%f\" % (np.sum(yhat.asnumpy()), np.var(yhat.asnumpy()), np.mean(yhat.asnumpy())))\n",
    "        #print(\"W sum:%f, var:%f, mean:%f\" % (np.sum(W.asnumpy()), np.var(W.asnumpy()), np.mean(W.asnumpy())))\n",
    "        #print(\"b sum:%f, var:%f, mean:%f\" % (np.sum(b.asnumpy()), np.var(b.asnumpy()), np.mean(b.asnumpy())))\n",
    "\n",
    "        for data,label in data_iter(batch_size=batch_size,kind='test'):\n",
    "            data  = data.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            yhat = net(data, net_type)\n",
    "            test_accu += accuracy(yhat, label)\n",
    "                \n",
    "        cur_time = datetime.datetime.now()\n",
    "        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "        m, s = divmod(remainder, 60)\n",
    "        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "        prev_time = cur_time\n",
    "        \n",
    "        print(\"\\r%s epoch:%d; loss:%f; Train accu:%f; Test accu:%f; Time:%s\" % (\n",
    "                        net_type, e, \n",
    "                        train_loss/len(train_labels)*batch_size,\n",
    "                        train_accu/len(train_labels)*batch_size,\n",
    "                        test_accu/len(test_labels)*batch_size,\n",
    "                        time_str))\n",
    "\n",
    "    print(datetime.datetime.now()-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wb epoch:0; loss:1.990911; Train accu:0.632633; Test accu:0.723500; Time:Time 00:00:01\n",
      "wb epoch:1; loss:1.134481; Train accu:0.743483; Test accu:0.758300; Time:Time 00:00:01\n",
      "wb epoch:2; loss:0.961380; Train accu:0.769050; Test accu:0.777200; Time:Time 00:00:01\n",
      "wb epoch:3; loss:0.866320; Train accu:0.781950; Test accu:0.787200; Time:Time 00:00:01\n",
      "wb epoch:4; loss:0.802320; Train accu:0.791517; Test accu:0.794900; Time:Time 00:00:01\n",
      "wb epoch:5; loss:0.754979; Train accu:0.798200; Test accu:0.798700; Time:Time 00:00:01\n",
      "wb epoch:6; loss:0.718040; Train accu:0.804000; Test accu:0.803100; Time:Time 00:00:01\n",
      "wb epoch:7; loss:0.688148; Train accu:0.808567; Test accu:0.807000; Time:Time 00:00:01\n",
      "wb epoch:8; loss:0.663303; Train accu:0.811733; Test accu:0.808900; Time:Time 00:00:01\n",
      "wb epoch:9; loss:0.642239; Train accu:0.815017; Test accu:0.811000; Time:Time 00:00:01\n",
      "0:00:16.242213\n"
     ]
    }
   ],
   "source": [
    "train(net_type='wb', params=wb_params, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp epoch:0; loss:0.652557; Train accu:0.765483; Test accu:0.834900; Time:Time 00:00:02\n",
      "mlp epoch:1; loss:0.435276; Train accu:0.842683; Test accu:0.855800; Time:Time 00:00:02\n",
      "mlp epoch:2; loss:0.389818; Train accu:0.859283; Test accu:0.866800; Time:Time 00:00:02\n",
      "mlp epoch:3; loss:0.362056; Train accu:0.868283; Test accu:0.874600; Time:Time 00:00:02\n",
      "mlp epoch:4; loss:0.341983; Train accu:0.875867; Test accu:0.880500; Time:Time 00:00:02\n",
      "0:00:10.255691\n"
     ]
    }
   ],
   "source": [
    "train(net_type='mlp', params=mlp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp_gluon epoch:0; loss:0.918494; Train accu:0.651183; Test accu:0.760200; Time:Time 00:00:01\n",
      "mlp_gluon epoch:1; loss:0.714639; Train accu:0.726967; Test accu:0.786400; Time:Time 00:00:02\n",
      "mlp_gluon epoch:2; loss:0.656104; Train accu:0.754450; Test accu:0.835300; Time:Time 00:00:02\n",
      "mlp_gluon epoch:3; loss:0.613184; Train accu:0.772083; Test accu:0.780600; Time:Time 00:00:01\n",
      "mlp_gluon epoch:4; loss:0.594230; Train accu:0.781583; Test accu:0.817800; Time:Time 00:00:01\n",
      "0:00:09.941778\n"
     ]
    }
   ],
   "source": [
    "train(net_type='mlp_gluon',trainer=get_trainer(mlp_net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenet epoch:0; loss:1.507709; Train accu:0.418667; Test accu:0.771100; Time:Time 00:00:06\n",
      "lenet epoch:1; loss:0.510878; Train accu:0.807533; Test accu:0.858800; Time:Time 00:00:06\n",
      "lenet epoch:2; loss:0.395434; Train accu:0.854750; Test accu:0.872800; Time:Time 00:00:06\n",
      "lenet epoch:3; loss:0.345393; Train accu:0.873133; Test accu:0.880500; Time:Time 00:00:06\n",
      "lenet epoch:4; loss:0.315531; Train accu:0.884317; Test accu:0.882800; Time:Time 00:00:06\n",
      "0:00:33.791102\n"
     ]
    }
   ],
   "source": [
    "train(net_type='lenet', params=lenet_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenet_gluon epoch:0; loss:0.563640; Train accu:0.789850; Test accu:0.868200; Time:Time 00:00:06\n",
      "lenet_gluon epoch:1; loss:0.348757; Train accu:0.869317; Test accu:0.883600; Time:Time 00:00:06\n",
      "lenet_gluon epoch:2; loss:0.309822; Train accu:0.883717; Test accu:0.888100; Time:Time 00:00:06\n",
      "lenet_gluon epoch:3; loss:0.285167; Train accu:0.892317; Test accu:0.888800; Time:Time 00:00:06\n",
      "lenet_gluon epoch:4; loss:0.268244; Train accu:0.898000; Test accu:0.890300; Time:Time 00:00:06\n",
      "0:00:32.280320\n"
     ]
    }
   ],
   "source": [
    "train(net_type='lenet_gluon', trainer=get_trainer(lenet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "   1 0%"
     ]
    },
    {
     "ename": "MXNetError",
     "evalue": "[19:09:27] src/storage/./pooled_storage_manager.h:108: cudaMalloc failed: out of memory\n\nStack trace returned 10 entries:\n[bt] (0) /home/kevin/workspace/pyvenv/py3venv/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x31f81a) [0x7f7f345d781a]\n[bt] (1) /home/kevin/workspace/pyvenv/py3venv/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x31fe41) [0x7f7f345d7e41]\n[bt] (2) /home/kevin/workspace/pyvenv/py3venv/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x29eea63) [0x7f7f36ca6a63]\n[bt] (3) /home/kevin/workspace/pyvenv/py3venv/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x29f3315) [0x7f7f36cab315]\n[bt] (4) /home/kevin/workspace/pyvenv/py3venv/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x459114) [0x7f7f34711114]\n[bt] (5) /home/kevin/workspace/pyvenv/py3venv/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2508b0d) [0x7f7f367c0b0d]\n[bt] (6) /home/kevin/workspace/pyvenv/py3venv/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2508fe3) [0x7f7f367c0fe3]\n[bt] (7) /home/kevin/workspace/pyvenv/py3venv/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2480fbd) [0x7f7f36738fbd]\n[bt] (8) /home/kevin/workspace/pyvenv/py3venv/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2480fa7) [0x7f7f36738fa7]\n[bt] (9) /home/kevin/workspace/pyvenv/py3venv/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2480fa7) [0x7f7f36738fa7]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-885c2812a182>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'vgg_gluon'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-2ffd9bedba44>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, learning_rate, net_type, params, trainer)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mtrain_accu\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#print(\"\\r\\nyhat sum:%f, var:%f, mean:%f\" % (np.sum(yhat.asnumpy()), np.var(yhat.asnumpy()), np.mean(yhat.asnumpy())))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/pyvenv/py3venv/lib/python3.5/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1894\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1896\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/pyvenv/py3venv/lib/python3.5/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1874\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1875\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1876\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   1877\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/pyvenv/py3venv/lib/python3.5/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \"\"\"\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: [19:09:27] src/storage/./pooled_storage_manager.h:108: cudaMalloc failed: out of memory\n\nStack trace returned 10 entries:\n[bt] (0) /home/kevin/workspace/pyvenv/py3venv/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x31f81a) [0x7f7f345d781a]\n[bt] (1) /home/kevin/workspace/pyvenv/py3venv/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x31fe41) [0x7f7f345d7e41]\n[bt] (2) /home/kevin/workspace/pyvenv/py3venv/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x29eea63) [0x7f7f36ca6a63]\n[bt] (3) /home/kevin/workspace/pyvenv/py3venv/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x29f3315) [0x7f7f36cab315]\n[bt] (4) /home/kevin/workspace/pyvenv/py3venv/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x459114) [0x7f7f34711114]\n[bt] (5) /home/kevin/workspace/pyvenv/py3venv/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2508b0d) [0x7f7f367c0b0d]\n[bt] (6) /home/kevin/workspace/pyvenv/py3venv/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2508fe3) [0x7f7f367c0fe3]\n[bt] (7) /home/kevin/workspace/pyvenv/py3venv/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2480fbd) [0x7f7f36738fbd]\n[bt] (8) /home/kevin/workspace/pyvenv/py3venv/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2480fa7) [0x7f7f36738fa7]\n[bt] (9) /home/kevin/workspace/pyvenv/py3venv/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2480fa7) [0x7f7f36738fa7]\n\n"
     ]
    }
   ],
   "source": [
    "train(net_type='vgg_gluon', trainer=get_trainer(vgg_net), epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statiser import Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#P310 上运行需要很长时间，且会跑死\n",
    "#vgg_net.load_parameters(\"/home/kevin/Downloads/devlab.zte/vgg-net-params-2018-08-31_18-20-37\", ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_lab_nd[:10].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net(train_img_nd[:10],net_type='mlp').argmax(axis=1).asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from statiser import Statistics\n",
    "\n",
    "tr1 = Statistics(net(train_img_nd,net_type='wb').argmax(axis=1).asnumpy(), train_lab_nd.asnumpy())\n",
    "tr1.show()\n",
    "tr2 = Statistics(net(train_img_nd,net_type='mlp').argmax(axis=1).asnumpy(), train_lab_nd.asnumpy())\n",
    "tr2.show()\n",
    "tr3 = Statistics(net(train_img_nd,net_type='mlp_gluon').argmax(axis=1).asnumpy(), train_lab_nd.asnumpy())\n",
    "tr3.show()\n",
    "tr4 = Statistics(net(train_img_nd[:100],net_type='lenet').argmax(axis=1).asnumpy(), train_lab_nd[:100].asnumpy())\n",
    "tr4.show()\n",
    "\n",
    "te1 = Statistics(net(test_img_nd,net_type='wb').argmax(axis=1).asnumpy(), test_lab_nd.asnumpy())\n",
    "te1.show()\n",
    "te2 = Statistics(net(test_img_nd,net_type='mlp').argmax(axis=1).asnumpy(), test_lab_nd.asnumpy())\n",
    "te2.show()\n",
    "te3 = Statistics(net(test_img_nd,net_type='mlp_gluon').argmax(axis=1).asnumpy(), test_lab_nd.asnumpy())\n",
    "te3.show()\n",
    "te4 = Statistics(net(test_img_nd[:100],net_type='lenet').argmax(axis=1).asnumpy(), test_lab_nd[:100].asnumpy())\n",
    "te4.show()\n",
    "\n",
    "plt.plot(range(10),tr1.Recall(),'r')\n",
    "plt.plot(range(10),tr1.Precision(),'g')\n",
    "plt.plot(range(10),te1.Recall(),'b')\n",
    "plt.plot(range(10),te1.Precision(),'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "816px",
    "left": "0px",
    "right": "1471px",
    "top": "107px",
    "width": "209px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
